import os
import pandas as pd
from skcriteria import Data, MAX
from skcriteria.madm import simple
import difflib
import re

# """ Opportunity to implement a Decorator for something in here !!!! 
#     Also, you need to generalize this to handle situations where it's not a dataframe, 
#         but a list, tuple, dictionary, etc. *** """
# """ Takes the unique values of a collection and replaces values that are nearly the same with one of em. 
#         Returns the dataframe. """
# def replace_values(dataframe, the_column):
#     """ Appends all the unique values in a dataframe column to a lits and returns the list """
#     def unique_values(dataframe, the_column, items=[]):
#         items = [i for i in dataframe[the_column].unique()]

#         return items

#     k = 0
#     for i in unique_values(dataframe, the_column):
#         for j in dataframe[the_column]:
#             seq = difflib.SequenceMatcher(None, i, j).ratio() * 100
#             # If the length of the list of unique column values has been exceeded, exit loop
#             print(k)
#             if k > len(dataframe[the_column]) + 1:
#                 print("BREAK!")
                
#             # If the two values are equal, keep it moving...
#             elif j == i:
#                 k += 1
#                 continue
#             # If the two values are nearly the same, replace one and make it the standard...
#             elif (seq >= 75) & (i != j):
#                 val = re.sub(i, j, i)
#                 dataframe[the_column].replace(to_replace=i, value=j, inplace=True)
#                 k += 1

#     return dataframe

os.chdir(r'C:\Users\cparker\Desktop')

df = pd.read_csv(r'C:\Users\cparker\Desktop\Copy of REID DDG BOS SHOES .csv')

""" Groups separate dataframes according to the part type and returns a dictionary """
def part_types(dataframe, the_column, part_type_dict={}):
    for _type in dataframe[the_column].unique():
        part_type_dict[_type] = dataframe.loc[dataframe[the_column] == _type]

    return part_type_dict

dfx = part_types(df, 'Std Part Description')

def get_dframe_groups(dataframe, the_column, *criteria):
    
    def min_max_scaling(feed_df):
        frame = feed_df.copy()

        for col in criteria:
            frame[col] = (frame[col] - frame[col].min()) / (frame[col].max() - frame[col].min())

        return frame

    locations = {}
    pre_df = {}

    for loc in dataframe[the_column].unique():
        locations[loc] = dataframe.loc[dataframe[the_column] == loc]
        # Refactor below... possibly using REGEX!
        pre_df[loc[13:]] = min_max_scaling(locations[loc])

    return pre_df
    

df_dict = get_dframe_groups(df, 'Location', 'Last 12 Mo Sales', 'Local Experian VIO', 'Local Vista Demand',
                'Alliance DW Region', 'Blended Coverage')

""" Returns a dictionary of dataframes """
def get_dframes():
    new_dframe = {}
    for loc in df_dict:
        for _type in df_dict[loc]['Std Part Description'].unique():
            new_dframe.__setitem__(loc+'_'+_type, df_dict[loc].loc[df_dict[loc]['Std Part Description'] == _type])
            
        # dframe = df_dict[loc][['Part', 'Last 12 Mo Sales', 'Local Experian VIO', 'Local Vista Demand',
        #             'Alliance DW Region', 'Blended Coverage']]

            

            criteria_data = Data(
                dframe.iloc[:, 1:],
                [MAX, MAX, MAX, MAX, MAX],
                anames=dframe['Part'],
                cnames=dframe.columns[1:],
                weights=[1, 1, 1.25, 1, 1]
            )

            dm = simple.WeightedProduct(mnorm="sum")
            dec = dm.decide(criteria_data)

            #Convert Ranks to Series to insert into DataFrame
            parts = pd.Series(dec.data.anames, name="Part")
            ranks = pd.Series(dec.rank_, name="Rank")
            ranked_df = pd.concat([parts, ranks], axis=1)

            og_df = df.loc[df['Location'].str.contains(loc)]
            new_dframe[loc] = og_df.merge(ranked_df, how='inner', on='Part')
            cols = new_dframe[loc].columns.to_list()
            cols = cols[:12] + cols[-1:] + cols[12: -1]
            new_dframe[loc] = new_dframe[loc][cols]

    return new_dframe
    

def format_workbook(dataframe, writer, name_of_sheet):
    dataframe.to_excel(writer, sheet_name=name_of_sheet, header=False,
            index=False, startrow=1)

    workbook = writer.book
    worksheet = writer.sheets[name_of_sheet]

    header_format = workbook.add_format({
        'bold': True,
        'align': 'center',
        'font_color': 'black'
    })
    header_format.set_rotation(90)

    for col, val in enumerate(dataframe.columns.values):
        worksheet.write(0, col, val, header_format)


with pd.ExcelWriter(r'UPDATES\newshit.xlsx', engine='xlsxwriter') as writ:
    for df in get_dframes().values():
        sheet = df['Location'][34][5:]
        format_workbook(dataframe=df, writer=writ, name_of_sheet=sheet)

